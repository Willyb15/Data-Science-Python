{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Exploration\n",
    "\n",
    "Today we're going to be analyzing a dataset of passengers on the Titanic and trying to predict who will survive.  To guide our efforts, first we'll be talking about a data science framework:  CRISP-DM\n",
    "\n",
    "![CRISP-DM Workflow](CRISP-DM_Process_Diagram.png)\n",
    "\n",
    "**CRISP-DM** (**CR**oss **I**ndustry **S**tandard **P**ractices for **D**ata **M**ining)  Is a way of structuring data science projects.  It emphasizes an \"agile\" methodology of continuous improvement and iteration, and consists of six steps:\n",
    "\n",
    "\n",
    "<br>\n",
    "**Business understanding**\n",
    "\n",
    "This initial phase focuses on understanding the project objectives and requirements from a business perspective, and then converting this knowledge into a data mining problem definition, and a preliminary plan designed to achieve the objectives. A decision model, especially one built using the Decision Model and Notation standard can be used.\n",
    "\n",
    "**Data understanding**\n",
    "\n",
    "The data understanding phase starts with an initial data collection and proceeds with activities in order to get familiar with the data, to identify data quality problems, to discover first insights into the data, or to detect interesting subsets to form hypotheses for hidden information.\n",
    "\n",
    "**Data preparation**\n",
    "    \n",
    "The data preparation phase covers all activities to construct the final dataset (data that will be fed into the modeling tool(s)) from the initial raw data. Data preparation tasks are likely to be performed multiple times, and not in any prescribed order. Tasks include table, record, and attribute selection as well as transformation and cleaning of data for modeling tools.\n",
    "\n",
    "**Modeling**\n",
    "    \n",
    "In this phase, various modeling techniques are selected and applied, and their parameters are calibrated to optimal values. Typically, there are several techniques for the same data mining problem type. Some techniques have specific requirements on the form of data. Therefore, stepping back to the data preparation phase is often needed.\n",
    "\n",
    "**Evaluation**\n",
    "    \n",
    "At this stage in the project you have built a model (or models) that appears to have high quality, from a data analysis perspective. Before proceeding to final deployment of the model, it is important to more thoroughly evaluate the model, and review the steps executed to construct the model, to be certain it properly achieves the business objectives. A key objective is to determine if there is some important business issue that has not been sufficiently considered. At the end of this phase, a decision on the use of the data mining results should be reached.\n",
    "\n",
    "**Deployment**\n",
    "    \n",
    "Creation of the model is generally not the end of the project. Even if the purpose of the model is to increase knowledge of the data, the knowledge gained will need to be organized and presented in a way that is useful to the customer. Depending on the requirements, the deployment phase can be as simple as generating a report or as complex as implementing a repeatable data scoring (e.g. segment allocation) or data mining process. In many cases it will be the customer, not the data analyst, who will carry out the deployment steps. Even if the analyst deploys the model it is important for the customer to understand up front the actions which will need to be carried out in order to actually make use of the created models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to concentrate our efforts on the Data Understanding, Data Preparation, and Modeling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's do it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO:\\n\\nRead in data\\nExamine columns (datatypes, relation to response, plots)\\nOutlier detection\\nDealing with missing values\\nCorrelation between features\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspiration taken from Yassine Ghouzam's Kaggle Kernel\n",
    "\n",
    "TODO:\n",
    "\n",
    "Read in data\n",
    "Examine columns (datatypes, relation to response, plots)\n",
    "Outlier detection\n",
    "Dealing with missing values\n",
    "Correlation between features\n",
    "Feature engineering (titles, family size, cabin, etc.)\n",
    "Train/test split\n",
    "Build LR model\n",
    "Compute accuracy\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.heatmap(train[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\n",
    "g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , palette = \"muted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
